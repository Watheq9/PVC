{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "sys.path.append('../') \n",
    "import os\n",
    "from helper import utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dict(df, columns, value=None):\n",
    "    \"\"\"\n",
    "    Create a dictionary where the keys are tuples of values from the specified columns,\n",
    "    and the values are set to the passed value (default is 1).\n",
    "\n",
    "    df: The input DataFrame.\n",
    "    columns: column names to use as keys.\n",
    "    \n",
    "    return: A dictionary with tuple keys\n",
    "    \"\"\"\n",
    "    if len(columns) < 1:\n",
    "        raise ValueError(\"At least one column must be specified.\")\n",
    "    \n",
    "    # Use zip to pair values from the specified columns\n",
    "    dict_result = {}\n",
    "    for row in df.itertuples():\n",
    "        key_list = []\n",
    "        for column in columns:\n",
    "            key_list.append(getattr(row, column))\n",
    "        key = tuple(key_list)\n",
    "        if value is None:\n",
    "            dict_result[key] = row\n",
    "        else:\n",
    "            dict_result[key] = value\n",
    "\n",
    "    # dict_result = {tuple(row): value for row in df[columns].itertuples(index=False, name=None)}\n",
    "    \n",
    "    return dict_result\n",
    "\n",
    "\n",
    "def check_save_dir(save_file):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(os.path.dirname(save_file)):\n",
    "        os.makedirs(os.path.dirname(save_file), exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def check_run_ranking(df):\n",
    "    # Sort by qid (ascending) and score (descending within each qid group)\n",
    "    df_sorted = df.sort_values(by=['qid', 'score'], ascending=[True, False])\n",
    "\n",
    "    # Make the ranking within each 'qid' group starting from 1\n",
    "    df_sorted['rank'] = df_sorted.groupby('qid').cumcount() + 1\n",
    "    df_sorted = df_sorted.reset_index(drop=True)\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "def sort_run_by_rank(run, save_path=\"\"):\n",
    "    df = utils.read_run(run)\n",
    "        # Get the sorted unique values of the third column dynamically\n",
    "    rank_sorted_values = sorted(df['rank'].unique())\n",
    "\n",
    "    # print(rank_sorted_values)\n",
    "    # Sort dynamically based on unique rank values\n",
    "    df_sorted = pd.concat([df[df['rank'] == val] for val in rank_sorted_values])\n",
    "\n",
    "    # Reset index for cleaner output\n",
    "    df_sorted = df_sorted.reset_index(drop=True)\n",
    "    if save_path != \"\":\n",
    "        df_sorted.to_csv(save_path, index=False, header=False, sep=\"\\t\")\n",
    "\n",
    "    return df_sorted\n",
    "\n",
    "\n",
    "\n",
    "def make_pool_rrf(list_of_runs, topX=500, rrf_den=60):\n",
    "    \"\"\"\n",
    "        topX = Number of documents per qid. Default: 500.\n",
    "        rrf_den = Value for the Reciprocal Rank Fusion denominator. Default is 60 as in the original paper:\n",
    "        Reciprocal Rank Fusion outperforms Condorcet and individual Rank Learning Methods. G. V. Cormack. University of Waterloo. Waterloo, Ontario, Canada.\n",
    "    \"\"\"\n",
    "\n",
    "    big_df = pd.DataFrame(columns=[\"qid\", \"docno\", \"rbp_value\"])\n",
    "    run_length = 0\n",
    "    for run in list_of_runs:\n",
    "        df = utils.read_run(run)\n",
    "        df['qid'] = df['qid'].astype(str)\n",
    "        df['docno'] = df['docno'].astype(str)\n",
    "        df = check_run_ranking(df)\n",
    "        # NOTE: Everything is made based on the rank col. It HAS TO start by '1'\n",
    "        df[\"rrf_value\"] = 1.0 / (rrf_den + df[\"rank\"])\n",
    "        df = df.groupby('qid').head(topX)\n",
    "        run_length += len(df)\n",
    "\n",
    "        # Concatenate all dfs into a single big_df\n",
    "        big_df = pd.concat([big_df, df[[\"qid\", \"docno\", \"rrf_value\"]]], ignore_index=True)\n",
    "        # big_df = pd.concat((big_df, df[[\"qid\", \"docno\", \"rrf_value\"]]), sort=True)\n",
    "\n",
    "    big_df['qid'] = big_df['qid'].astype(str)\n",
    "    big_df['docno'] = big_df['docno'].astype(str)\n",
    "    # Default startegy is the sum.\n",
    "    # grouped_by_docno = big_df.groupby([\"qid\", \"docno\"])[\"rrf_value\"].sum().reset_index()\n",
    "    grouped_by_docno = big_df.groupby([\"qid\", \"docno\"], as_index=False)['rrf_value'].sum()\n",
    "\n",
    "    # Sort documents by rbp value inside each qid group\n",
    "    grouped_by_docno.sort_values(by=[\"qid\", \"rrf_value\"], ascending=[True, False], inplace=True)\n",
    "\n",
    "    # Selects only the top X from each query\n",
    "    # result = grouped_by_docno.groupby(\"qid\").head(topX)\n",
    "\n",
    "    # Transform pandas data into a dictionary\n",
    "    pool = {}\n",
    "    pool_with_rrf = {}\n",
    "    query_doc_dict = {}\n",
    "    for row in grouped_by_docno[[\"qid\", \"docno\", \"rrf_value\"]].itertuples():\n",
    "        # q = int(row.qid)\n",
    "        qid = str(row.qid)\n",
    "        rrf_value = row.rrf_value\n",
    "        docno = str(row.docno)\n",
    "        if qid not in pool:\n",
    "            pool[qid] = set([])\n",
    "            pool_with_rrf[qid] = {}\n",
    "\n",
    "        if docno not in pool[qid]:\n",
    "            pool[qid].add(docno)\n",
    "            pool_with_rrf[qid].update({docno: rrf_value})\n",
    "\n",
    "\n",
    "        line_pair = (qid, docno)\n",
    "        # print(int(row.rank))\n",
    "        # assert rank == int(row.rank)\n",
    "        # rank += 1\n",
    "        if query_doc_dict.get(line_pair, 0) == 0:\n",
    "            query_doc_dict[line_pair] = 1\n",
    "\n",
    "    dict_len = 0\n",
    "    for qid in pool_with_rrf.keys():\n",
    "        dict_len += len(pool_with_rrf[qid])\n",
    "    \n",
    "    unique_cnt = len(grouped_by_docno)\n",
    "    assert unique_cnt == dict_len\n",
    "    print(f\"Number of rows of the joined dataframe (big_df) at depth {topX} is {len(big_df)}, unique pairs = {len(grouped_by_docno)}, num queries = {len(pool_with_rrf)}\")\n",
    "    return pool_with_rrf, run_length, unique_cnt\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def save_pool_as_trec_run(pool_with_rrf, run_file, tag='unified_pool', sort_by_rank=True):\n",
    "    \n",
    "    check_save_dir(run_file)\n",
    "    with open(run_file, \"w\") as fout:\n",
    "        for qid, document_rrf in sorted(iter(list(pool_with_rrf.items())), key=lambda x: x[0]):\n",
    "            # document_rrf = dict(document_rrf)\n",
    "            rank = 1\n",
    "            for docno, rrf in sorted(iter(list(document_rrf.items())),  key=lambda x: x[1], reverse=True):\n",
    "                rrf = round(rrf, 6)\n",
    "                line = f\"{str(qid)}\\tQ0\\t{docno}\\t{rank}\\t{rrf}\\t{tag}\\n\"\n",
    "                rank += 1\n",
    "                fout.write(line)\n",
    "    print(f\"Unified run was saved to {run_file}\")\n",
    "    if sort_by_rank:\n",
    "        sort_run_by_rank(run_file, save_path=run_file)\n",
    "\n",
    "\n",
    "def map_query_var_to_orig_query(rrf_run, save_path):\n",
    "    df = utils.read_run(rrf_run)\n",
    "    query_doc_dict = create_dict(df, columns=['qid', 'docno'])\n",
    "\n",
    "    orig_qids = []\n",
    "    qids = []\n",
    "    unique_rows = []\n",
    "    unique_query_doc_dict = {}\n",
    "    for (qid, docno), row in query_doc_dict.items():\n",
    "        qid_orig = qid if len(qid.split(\"_\")) <= 1 else \"QV_\"+qid.split(\"_\")[1]\n",
    "        qid = qid.split(\"_\")[0]\n",
    "        qid = str(qid)\n",
    "        qid_orig = str(qid_orig)\n",
    "        if unique_query_doc_dict.get((qid, docno), 0) == 0:\n",
    "            unique_query_doc_dict[(qid, docno)] = row\n",
    "            qids.append(qid)\n",
    "            unique_rows.append(row)\n",
    "            orig_qids.append(qid_orig)\n",
    "\n",
    "\n",
    "    df_unified = pd.DataFrame(unique_rows)\n",
    "    df_unified['qid'] = qids # store the \n",
    "    df_unified['Q0'] = orig_qids # store the \n",
    "    # print(df_unified.info())\n",
    "    df_unified = df_unified.drop(['Index'], axis=1) # drop the index column created by pandas\n",
    "    df_unified.to_csv(save_path, index=False, header=False, sep=\"\\t\")\n",
    "    print(f\"Number of unique query-document pairs after mapping query variations to original query ids is {len(unique_query_doc_dict)}\")\n",
    "    return df_unified, unique_query_doc_dict\n",
    "\n",
    "\n",
    "def get_model_runs(tr_model, runs_dir):\n",
    "    run_names = []\n",
    "    for root, dirs, files in os.walk(runs_dir):\n",
    "        for filename in files:\n",
    "            run_file = os.path.join(root, filename)\n",
    "            if filename.startswith(tr_model) and filename.endswith(\".tsv\"):\n",
    "                run_names.append(run_file)\n",
    "\n",
    "    return run_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_query_var_to_separate_runs(rrf_run, save_dir):\n",
    "    df = utils.read_run(rrf_run)\n",
    "    qids = []\n",
    "    qids = list(df['qid'].unique())\n",
    "    df_copy = df.copy()\n",
    "    for qid in qids:\n",
    "        qid_orig = str(qid.split(\"_\")[0])\n",
    "        df_q = df.loc[df.qid == qid, :].copy()\n",
    "        df_q['qid'] = [qid_orig for _ in range(len(df_q))]\n",
    "        df_q['Q0'] = [qid for _ in range(len(df_q))]\n",
    "        run_path = f\"{save_dir}/{qid_orig}/{qid}.tsv\"\n",
    "        check_save_dir(run_path)\n",
    "        df_q.to_csv(run_path, sep='\\t', index=False, header=False)\n",
    "\n",
    "    assert df.equals(df_copy) == True\n",
    "    return \n",
    "\n",
    "def get_runs_in_dir(runs_dir):\n",
    "    run_names = []\n",
    "    for root, dirs, files in os.walk(runs_dir):\n",
    "        for filename in files:\n",
    "            run_file = os.path.join(root, filename)\n",
    "            if filename.endswith(\".tsv\"):\n",
    "                run_names.append(run_file)\n",
    "    return run_names\n",
    "\n",
    "\n",
    "def fuse_runs_per_topic(model_runs_dir, fused_save_dir):\n",
    "    model_topics_dir = [(dir, os.path.join(model_runs_dir, dir)) for dir in os.listdir(model_runs_dir) if os.path.isdir(os.path.join(model_runs_dir, dir))]\n",
    "    # print(len(model_topics_dir))\n",
    "    total_len = 0\n",
    "    total_unique = 0\n",
    "    for (topic, topic_runs_dir) in model_topics_dir:\n",
    "        print(f\"Merging the runs of topic {topic} from directory: {topic_runs_dir}\")\n",
    "        topic_runs = get_runs_in_dir(topic_runs_dir)\n",
    "        topic_fused_run = f\"{fused_save_dir}/{topic}.tsv\"\n",
    "        check_save_dir(topic_fused_run)\n",
    "        pool_with_rrf, run_length, unique_cnt = make_pool_rrf(filenames=topic_runs, topX=1000, rrf_den=60)\n",
    "        total_len += run_length\n",
    "        total_unique += unique_cnt\n",
    "        save_pool_as_trec_run(pool_with_rrf, run_file=topic_fused_run, tag='fused_topic', sort_by_rank=False)\n",
    "\n",
    "    print(f\"total_len = {total_len}, total_unique= {total_unique}\")\n",
    "    return \n",
    "\n",
    "\n",
    "\n",
    "def fuse_topics_into_run(topics_dir, run_path, num_of_parts=1):\n",
    "    '''\n",
    "    topics_dir: directory containg the runs of each topic (should have 100 file per transcription model)\n",
    "    run_path: path to save the combined run\n",
    "    num_of_parts: number of files needed to split the combined run to.\n",
    "    '''\n",
    "    model_runs = get_runs_in_dir(topics_dir)\n",
    "    df_merged = pd.DataFrame()\n",
    "    cnt = 0\n",
    "    for run in model_runs:\n",
    "        df_run = utils.read_run(run)\n",
    "        cnt += len(df_run)\n",
    "        df_merged = pd.concat([df_merged, df_run], ignore_index=True)\n",
    "        # print(f\"{len(df_run)} rows read from run {run}\")\n",
    "    \n",
    "    # assert cnt == len(df_merged)\n",
    "    print(f\"Number of rows is {len(df_merged)} after merging runs from {topics_dir}\")\n",
    "\n",
    "    # sort the merged dataframe by rank so that top scored segment per query comes first, and then second top segment and so on\n",
    "    rank_sorted_values = sorted(df_merged['rank'].unique())\n",
    "    # Sort dynamically based on unique rank values\n",
    "    df_merged = pd.concat([df_merged[df_merged['rank'] == val] for val in rank_sorted_values])\n",
    "    # Reset index for cleaner output\n",
    "    # df_merged = df_merged.reset_index(drop=True)\n",
    "\n",
    "    start_idx = 0\n",
    "    end_idx = len(df_merged) -1\n",
    "    step = int(len(df_merged)/ num_of_parts + 1)\n",
    "    for i in range(num_of_parts):\n",
    "        start_idx = i * step\n",
    "        end_idx = min(len(df_merged), start_idx + step - 1)\n",
    "        run_part = f\"{run_path}_p{i+1}.tsv\"\n",
    "        check_save_dir(run_part)\n",
    "        df_merged.iloc[start_idx:end_idx].to_csv(run_part, index=False, sep='\\t', header=False)\n",
    "        print(f\"part {i+1} will be from row {start_idx} to {end_idx} and will be saved to {run_part}\")\n",
    "\n",
    "\n",
    "\n",
    "def form_pairs(input_file, query_dict, doc_dict, result, logger, input_type='run', save_format='jsonl', clean_text=True):\n",
    "    if input_type == \"run\":\n",
    "        df_input = utils.read_run(input_file)\n",
    "    else:\n",
    "        df_input = utils.read_qrels(input_file)\n",
    "    \n",
    "    logger.info(f\"Loaded the query and input files successfully.\")\n",
    "    df_input['q_description'] = df_input['qid'].map(query_dict)\n",
    "    df_input['doc_text'] = df_input['docno'].map(doc_dict)\n",
    "    if clean_text:\n",
    "        df_input['doc_text'] = df_input['doc_text'].apply(utils.clean_string)\n",
    "\n",
    "    save_columns = [\"qid\", \"docno\", \"q_description\", \"doc_text\"]\n",
    "\n",
    "    if save_format =='jsonl':\n",
    "        df_input[save_columns].to_json(result, index=False, orient='records', lines=True)\n",
    "    else: # tsv\n",
    "        df_input[save_columns].to_csv(result, index=False, sep='\\t',)\n",
    "\n",
    "    logger.info(f\"Done writing {len(df_input)} pairs to {result}\")\n",
    "\n",
    "\n",
    "def load_query(query_file, clean_text=True):\n",
    "    df_query = utils.read_query(query_file)\n",
    "    if clean_text:\n",
    "        df_query['description'] = df_query['description'].apply(utils.clean_string)\n",
    "    query_dict = {}\n",
    "    for row in df_query.itertuples():\n",
    "        query_dict[row.qid] = row.description\n",
    "    return query_dict\n",
    "\n",
    "\n",
    "def load_corpus(corpus_file, logger):\n",
    "    doc_dict = {}\n",
    "    df_doc = utils.read_jsonl(corpus_file)\n",
    "    logger.info(f\"Done loading corpus from {corpus_file}.\")\n",
    "    for row in df_doc.itertuples():\n",
    "        doc_dict[row.id] = getattr(row, \"seg_words\")\n",
    "    return doc_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_models = [\"spotify\" ,\n",
    "        \"whisperX-base\" ,\n",
    "        \"whisperX-large-v3\",\n",
    "        \"silero-large\",\n",
    "        \"silero-small\"\n",
    "        ]\n",
    "\n",
    "project_dir = \"your_project_dir\"\n",
    "pool_dir=f\"{project_dir}/data/runs/pool\"\n",
    "rrf_dir = f\"{project_dir}/data/runs/pool_rrf\"\n",
    "final_run_dir = f\"{rrf_dir}/st4_final_runs\"\n",
    "pairs_dir = f\"{rrf_dir}/st5_judgement_pairs\"\n",
    "query_file = f\"{project_dir}/data/queries/podcasts_2020_and_2021_topics_test_with_description.tsv\"\n",
    "corpus_dir = f\"{project_dir}/data/corpus\"\n",
    "log_dir =f\"{project_dir}/data/logs/pool\"\n",
    "\n",
    "query_dict = load_query(query_file)\n",
    "\n",
    "\n",
    "for tr_model in tr_models:\n",
    "    model_runs = get_model_runs(tr_model, pool_dir)\n",
    "    rrf_run = f'{rrf_dir}/st1_fuse_system_runs/{tr_model}_rrf.tsv'\n",
    "    separated_topics_dir = f\"{rrf_dir}/st2_fuse_query_variations/{tr_model}\"\n",
    "    fused_topics_dir = f\"{rrf_dir}/st3_fuse_topics_runs/{tr_model}\"\n",
    "    final_run = f\"{rrf_dir}/st4_final_runs/{tr_model}\"\n",
    "\n",
    "    print(f\"Forming unified run for {tr_model} out of {len(model_runs)} runs and unified run will be saved to {rrf_run}\")\n",
    "    # 1. Fuse the pool runs using RRF\n",
    "    pool_with_rrf, _, _ = make_pool_rrf(filenames=model_runs, topX=10, rrf_den=60)\n",
    "    save_pool_as_trec_run(pool_with_rrf, run_file=rrf_run, tag='unified_pool', sort_by_rank=True)\n",
    "\n",
    "    # 2. Converted query variations to their original query id and saved them as separate runs\n",
    "    convert_query_var_to_separate_runs(rrf_run, save_dir=separated_topics_dir)\n",
    "\n",
    "    # 3. Fused runs per topic\n",
    "    fuse_runs_per_topic(model_runs_dir=separated_topics_dir, fused_save_dir=fused_topics_dir)\n",
    "\n",
    "    # 4. Fuse the topics runs into one run (or multiple parts), and sort the result by rank, i.e., top scored segments first\n",
    "    # change num_of_parts parameter value as needed\n",
    "    fuse_topics_into_run(topics_dir=fused_topics_dir, run_path=final_run, num_of_parts=1)\n",
    "\n",
    "\n",
    "\n",
    "for tr_model in tr_models:\n",
    "    model_runs = get_model_runs(tr_model, final_run_dir)\n",
    "    corpus=f\"{corpus_dir}/{tr_model}_120_60_time_segment.jsonl\"\n",
    "    log_file = f\"{log_dir}/form_pairs_{tr_model}.log\"\n",
    "    logger = utils.get_logger(log_file)\n",
    "    doc_dict = load_corpus(corpus, logger)\n",
    "\n",
    "    for run in model_runs:\n",
    "        run_name = os.path.basename(run).split('.')[0]+\"_pairs.jsonl\"\n",
    "        pairs_file = f\"{pairs_dir}/{run_name}\"\n",
    "        logger.info(f\"forming the pairs from run on: {run}, and pairs file will be saved to {pairs_file}\")\n",
    "        # 5. form the pairs files for LLM judgement, by including the query description and segment txt\n",
    "        form_pairs(input_file=run, query_dict=query_dict, doc_dict=doc_dict, result=pairs_file, logger=logger,\n",
    "                input_type='run', save_format='jsonl', clean_text=True)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podcast-LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
